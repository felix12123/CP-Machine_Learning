{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZnAfRHXFXBa"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "O3PDeG-TFXBi"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7f640_iBFXBy"
      },
      "source": [
        "---\n",
        "## Lade Daten"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpZ4C_jWFXB0",
        "outputId": "f679e070-0a3c-40df-8b35-b667db3b0f0b"
      },
      "outputs": [],
      "source": [
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# number of subprocesses to use for data loading\n",
        "num_workers = 0\n",
        "# how many samples per batch to load\n",
        "batch_size = 20\n",
        "\n",
        "# convert data to torch.FloatTensor\n",
        "transform = transforms.ToTensor()\n",
        "\n",
        "# choose the training and test datasets\n",
        "train_data = datasets.MNIST(root='data', train=True,\n",
        "                                   download=True, transform=transform)\n",
        "test_data = datasets.MNIST(root='data', train=False,\n",
        "                                  download=True, transform=transform)\n",
        "\n",
        "# prepare data loaders\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size,\n",
        "    num_workers=num_workers)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size,\n",
        "    num_workers=num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPdizIw8FXB9"
      },
      "source": [
        "---\n",
        "## Visualisierung 1 Batch für Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "4IgEGPnyFXB_",
        "outputId": "dcea9d86-a9b3-4f74-943f-f069ebd0f2f9"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# obtain one batch of training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with the corresponding labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20 // 2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    # print out the correct label for each image\n",
        "    # .item() gets the value contained in a Tensor\n",
        "    ax.set_title(str(labels[idx].item()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ima93w8NFXCH"
      },
      "source": [
        "---\n",
        "## Details"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 984
        },
        "id": "yyA4AY-1FXCJ",
        "outputId": "21c17576-2121-4b0b-838d-dbdc78c88fdf"
      },
      "outputs": [],
      "source": [
        "img = np.squeeze(images[1])\n",
        "\n",
        "fig = plt.figure(figsize = (12,12))\n",
        "ax = fig.add_subplot(111)\n",
        "ax.imshow(img, cmap='gray')\n",
        "width, height = img.shape\n",
        "thresh = img.max()/2.5\n",
        "for x in range(width):\n",
        "    for y in range(height):\n",
        "        val = round(img[x][y],2) if img[x][y] !=0 else 0\n",
        "        ax.annotate(str(val), xy=(y,x),\n",
        "                    horizontalalignment='center',\n",
        "                    verticalalignment='center',\n",
        "                    color='white' if img[x][y]<thresh else 'black')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFJNBoz1FXCR"
      },
      "source": [
        "---\n",
        "## Definiere Netzwerkstruktur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrZa0yg7FXCT",
        "outputId": "744711d2-d088-4c62-f6da-3a493c6b9d6a"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "## TODO: Define the NN architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        # Nutze für Aufgabe (2.3) 3 convolutional Layer:\n",
        "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(8, 10, kernel_size=3)\n",
        "        self.conv3 = nn.Conv2d(10, 10, kernel_size=3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "\n",
        "        # Füge für 2 fully-connected Layer ein: \n",
        "        self.fc1 = nn.Linear(10* 11 * 11, 10)     # Hier bie A2.1 sollt eig das Letzte arguemtn 10 sein\n",
        "        self.fc2 = nn.Linear(10, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # Conv. Layer vor dem Flattening anwenden:\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "\n",
        "        # Flattening ausführen & Shape anpassen(!):\n",
        "        x = x.view(batch_size, 10 * 11 * 11)\n",
        "\n",
        "        # Wende relu auf die beiden darauffolgenden fully-connected Layer an:\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "\n",
        "# initialize the NN\n",
        "model = Net()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWAMd-YGFXCX"
      },
      "source": [
        "---\n",
        "##  Loss-Funktion und Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "PcZDKQhpFXCa"
      },
      "outputs": [],
      "source": [
        "# Funktionen entstammen der Doku von PyTorch\n",
        "\n",
        "# specify loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# specify optimizer\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COyDVXVRFXCh"
      },
      "source": [
        "---\n",
        "## Trainiere Netzwerk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zGoNDTYFXCj",
        "outputId": "09521965-c8c0-425f-f9e9-fa74dd68b4a2"
      },
      "outputs": [],
      "source": [
        "# number of epochs to train the model\n",
        "n_epochs = 5  # suggest training between 20-50 epochs\n",
        "\n",
        "model.train() # prep model for training\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # monitor training loss\n",
        "    train_loss = 0.0\n",
        "\n",
        "    ###################\n",
        "    # train the model #\n",
        "    ###################\n",
        "    for data, target in train_loader:\n",
        "        # clear the gradients of all optimized variables\n",
        "        optimizer.zero_grad()\n",
        "        # forward pass: compute predicted outputs by passing inputs to the model\n",
        "        output = model(data)\n",
        "        # calculate the loss\n",
        "        loss = criterion(output, target)\n",
        "        # backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "        # update running training loss\n",
        "        train_loss += loss.item()*data.size(0)\n",
        "\n",
        "    # print training statistics\n",
        "    # calculate average loss over an epoch\n",
        "    train_loss = train_loss/len(train_loader.sampler)\n",
        "\n",
        "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(\n",
        "        epoch+1,\n",
        "        train_loss\n",
        "        ))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_ROQbSUFXCo"
      },
      "source": [
        "---\n",
        "## Resultate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHFa0xlkFXCq",
        "outputId": "009f18a7-7225-4bf5-d2ef-e834abe457f4"
      },
      "outputs": [],
      "source": [
        "# initialize lists to monitor test loss and accuracy\n",
        "test_loss = 0.0\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "\n",
        "model.eval() # prep model for *evaluation*\n",
        "println(model.parameters)\n",
        "\n",
        "for data, target in test_loader:\n",
        "    # forward pass: compute predicted outputs by passing inputs to the model\n",
        "    output = model(data)\n",
        "    # calculate the loss\n",
        "    loss = criterion(output, target)\n",
        "    # update test loss\n",
        "    test_loss += loss.item()*data.size(0)\n",
        "    # convert output probabilities to predicted class\n",
        "    _, pred = torch.max(output, 1)\n",
        "    # compare predictions to true label\n",
        "    correct = np.squeeze(pred.eq(target.data.view_as(pred)))\n",
        "    # calculate test accuracy for each object class\n",
        "    for i in range(len(target)):\n",
        "        label = target.data[i]\n",
        "        class_correct[label] += correct[i].item()\n",
        "        class_total[label] += 1\n",
        "\n",
        "# calculate and print avg test loss\n",
        "test_loss = test_loss/len(test_loader.sampler)\n",
        "print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
        "\n",
        "for i in range(10):\n",
        "    if class_total[i] > 0:\n",
        "        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n",
        "            str(i), 100 * class_correct[i] / class_total[i],\n",
        "            np.sum(class_correct[i]), np.sum(class_total[i])))\n",
        "    else:\n",
        "        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n",
        "\n",
        "print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n",
        "    100. * np.sum(class_correct) / np.sum(class_total),\n",
        "    np.sum(class_correct), np.sum(class_total)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31-4ZSNdFXCy"
      },
      "source": [
        "## Visualisiere Ergebnisse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 273
        },
        "id": "zPSC3_J_FXC0",
        "outputId": "d5d83f3e-2e0d-4c31-c68f-483e3c5f1be5"
      },
      "outputs": [],
      "source": [
        "# obtain one batch of test images\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "\n",
        "# get sample outputs\n",
        "output = model(images)\n",
        "# convert output probabilities to predicted class\n",
        "_, preds = torch.max(output, 1)\n",
        "# prep images for display\n",
        "images = images.numpy()\n",
        "\n",
        "# plot the images in the batch, along with predicted and true labels\n",
        "fig = plt.figure(figsize=(25, 4))\n",
        "for idx in np.arange(20):\n",
        "    ax = fig.add_subplot(2, 20 // 2, idx+1, xticks=[], yticks=[])\n",
        "    ax.imshow(np.squeeze(images[idx]), cmap='gray')\n",
        "    ax.set_title(\"{} ({})\".format(str(preds[idx].item()), str(labels[idx].item())),\n",
        "                 color=(\"green\" if preds[idx]==labels[idx] else \"red\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Anmerkungen zu Aufgabe 2.3\n",
        "\n",
        "- Auf Grund der hohen RunTime habe ich das Programm lediglich 5 Epochen lang laufen lassen. Erhöht man die Epochen, so würde sich die Präzision wahrscheinlich nur marginal erhöhen, wohl eher würde sie ab einem gewissen Niveau anfangen zu stagnieren und marginal um einen geiwissen Wert (~98-99%) herum beifnden.\n",
        "\n",
        "- Durch die Anwendung der relu Funktion auf das letzte fully-connected Layer gewinnt man nochmal 1% Genauigkeit.\n",
        "\n",
        "- Die Verwendung von 3 conv. Layern ist in diesem Beispiel essentiell. Ohne das 3. Layer erhält man lediglich eine Genauigkeit von 59%. Ebenso essentiell ist die Verwendung von einem zweiten fully-connected Layer. Ohne dieses kann die Zahl 8 nicht erkannt werden. Dadurch stürtzt die Genauigkeit von 98% auf 88% ab.\n",
        "\n",
        "- Durch die Erhöhung des \"momentum\"-flag im Optimizer wurden die Ergebnisse ungenauer (~70-80%)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## GitHub\n",
        "\n",
        "Nachfolgend der GitHub Link zum Repo für diesen Praktikumsversuch. Dort sind folgende Unterlagen hinterlegt:\n",
        "\n",
        "- JULIA Implementation der Lösungen zu den Aufgaben\n",
        "- Jupyter Notebook Implementation der Lösungen zu den Aufgaben\n",
        "\n",
        "https://github.com/felix12123/CP-Machine_Learning"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "anaconda-cloud": {},
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
